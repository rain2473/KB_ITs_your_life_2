{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4d45d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DNN으로 숫자 신경망\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "mnist = tf.keras.datasets.mnist.load_data()\n",
    "print(type(mnist), len(mnist))\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "print(y_train[:5])\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.imshow(X_train[i], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edf5109a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ce50b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>126</td>\n",
       "      <td>136</td>\n",
       "      <td>175</td>\n",
       "      <td>26</td>\n",
       "      <td>166</td>\n",
       "      <td>255</td>\n",
       "      <td>247</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>94</td>\n",
       "      <td>154</td>\n",
       "      <td>170</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>225</td>\n",
       "      <td>172</td>\n",
       "      <td>253</td>\n",
       "      <td>242</td>\n",
       "      <td>195</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>238</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>251</td>\n",
       "      <td>93</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>56</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>219</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>198</td>\n",
       "      <td>182</td>\n",
       "      <td>247</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>156</td>\n",
       "      <td>107</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>205</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>154</td>\n",
       "      <td>253</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>253</td>\n",
       "      <td>190</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>190</td>\n",
       "      <td>253</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>241</td>\n",
       "      <td>225</td>\n",
       "      <td>160</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>240</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>119</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>186</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>150</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>93</td>\n",
       "      <td>252</td>\n",
       "      <td>253</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>249</td>\n",
       "      <td>253</td>\n",
       "      <td>249</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>130</td>\n",
       "      <td>183</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>207</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>148</td>\n",
       "      <td>229</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>250</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>114</td>\n",
       "      <td>221</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>201</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>66</td>\n",
       "      <td>213</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>198</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>171</td>\n",
       "      <td>219</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>195</td>\n",
       "      <td>80</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>172</td>\n",
       "      <td>226</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>244</td>\n",
       "      <td>133</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>212</td>\n",
       "      <td>135</td>\n",
       "      <td>132</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3    4    5    6    7    8    9    10   11   12   13   14  \\\n",
       "0    0   0   0   0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "1    0   0   0   0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2    0   0   0   0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "3    0   0   0   0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "4    0   0   0   0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "5    0   0   0   0    0    0    0    0    0    0    0    0    3   18   18   \n",
       "6    0   0   0   0    0    0    0    0   30   36   94  154  170  253  253   \n",
       "7    0   0   0   0    0    0    0   49  238  253  253  253  253  253  253   \n",
       "8    0   0   0   0    0    0    0   18  219  253  253  253  253  253  198   \n",
       "9    0   0   0   0    0    0    0    0   80  156  107  253  253  205   11   \n",
       "10   0   0   0   0    0    0    0    0    0   14    1  154  253   90    0   \n",
       "11   0   0   0   0    0    0    0    0    0    0    0  139  253  190    2   \n",
       "12   0   0   0   0    0    0    0    0    0    0    0   11  190  253   70   \n",
       "13   0   0   0   0    0    0    0    0    0    0    0    0   35  241  225   \n",
       "14   0   0   0   0    0    0    0    0    0    0    0    0    0   81  240   \n",
       "15   0   0   0   0    0    0    0    0    0    0    0    0    0    0   45   \n",
       "16   0   0   0   0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "17   0   0   0   0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "18   0   0   0   0    0    0    0    0    0    0    0    0    0    0   46   \n",
       "19   0   0   0   0    0    0    0    0    0    0    0    0   39  148  229   \n",
       "20   0   0   0   0    0    0    0    0    0    0   24  114  221  253  253   \n",
       "21   0   0   0   0    0    0    0    0   23   66  213  253  253  253  253   \n",
       "22   0   0   0   0    0    0   18  171  219  253  253  253  253  195   80   \n",
       "23   0   0   0   0   55  172  226  253  253  253  253  244  133   11    0   \n",
       "24   0   0   0   0  136  253  253  253  212  135  132   16    0    0    0   \n",
       "25   0   0   0   0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "26   0   0   0   0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "27   0   0   0   0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "     15   16   17   18   19   20   21   22   23  24  25  26  27  \n",
       "0     0    0    0    0    0    0    0    0    0   0   0   0   0  \n",
       "1     0    0    0    0    0    0    0    0    0   0   0   0   0  \n",
       "2     0    0    0    0    0    0    0    0    0   0   0   0   0  \n",
       "3     0    0    0    0    0    0    0    0    0   0   0   0   0  \n",
       "4     0    0    0    0    0    0    0    0    0   0   0   0   0  \n",
       "5    18  126  136  175   26  166  255  247  127   0   0   0   0  \n",
       "6   253  253  253  225  172  253  242  195   64   0   0   0   0  \n",
       "7   253  253  251   93   82   82   56   39    0   0   0   0   0  \n",
       "8   182  247  241    0    0    0    0    0    0   0   0   0   0  \n",
       "9     0   43  154    0    0    0    0    0    0   0   0   0   0  \n",
       "10    0    0    0    0    0    0    0    0    0   0   0   0   0  \n",
       "11    0    0    0    0    0    0    0    0    0   0   0   0   0  \n",
       "12    0    0    0    0    0    0    0    0    0   0   0   0   0  \n",
       "13  160  108    1    0    0    0    0    0    0   0   0   0   0  \n",
       "14  253  253  119   25    0    0    0    0    0   0   0   0   0  \n",
       "15  186  253  253  150   27    0    0    0    0   0   0   0   0  \n",
       "16   16   93  252  253  187    0    0    0    0   0   0   0   0  \n",
       "17    0    0  249  253  249   64    0    0    0   0   0   0   0  \n",
       "18  130  183  253  253  207    2    0    0    0   0   0   0   0  \n",
       "19  253  253  253  250  182    0    0    0    0   0   0   0   0  \n",
       "20  253  253  201   78    0    0    0    0    0   0   0   0   0  \n",
       "21  198   81    2    0    0    0    0    0    0   0   0   0   0  \n",
       "22    9    0    0    0    0    0    0    0    0   0   0   0   0  \n",
       "23    0    0    0    0    0    0    0    0    0   0   0   0   0  \n",
       "24    0    0    0    0    0    0    0    0    0   0   0   0   0  \n",
       "25    0    0    0    0    0    0    0    0    0   0   0   0   0  \n",
       "26    0    0    0    0    0    0    0    0    0   0   0   0   0  \n",
       "27    0    0    0    0    0    0    0    0    0   0   0   0   0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pd.DataFrame(X_train[0])\n",
    "pd.options.display.max_rows = 28\n",
    "pd.options.display.max_columns = 28\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4d6f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "(X_train,X_test) = (np.float32(X_train)/255.0,np.float32(X_test)/255.0)\n",
    "\n",
    "n_input = 28 * 28\n",
    "(X_train,X_test) = (X_train.reshape(-1,n_input),X_test.reshape(-1,n_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d4a0388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "       0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117648, 0.36862746, 0.6039216 ,\n",
       "       0.6666667 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235295, 0.6745098 , 0.99215686, 0.9490196 ,\n",
       "       0.7647059 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215687, 0.93333334,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.9843137 , 0.3647059 ,\n",
       "       0.32156864, 0.32156864, 0.21960784, 0.15294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.85882354, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.7137255 ,\n",
       "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.3137255 , 0.6117647 , 0.41960785, 0.99215686, 0.99215686,\n",
       "       0.8039216 , 0.04313726, 0.        , 0.16862746, 0.6039216 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "       0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54509807,\n",
       "       0.99215686, 0.74509805, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04313726, 0.74509805, 0.99215686,\n",
       "       0.27450982, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.13725491, 0.94509804, 0.88235295, 0.627451  ,\n",
       "       0.42352942, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31764707, 0.9411765 , 0.99215686, 0.99215686, 0.46666667,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "       0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.3647059 ,\n",
       "       0.9882353 , 0.99215686, 0.73333335, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.9764706 , 0.99215686,\n",
       "       0.9764706 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.50980395,\n",
       "       0.7176471 , 0.99215686, 0.99215686, 0.8117647 , 0.00784314,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "       0.5803922 , 0.8980392 , 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.98039216, 0.7137255 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.25882354, 0.8352941 , 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.31764707,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.67058825, 0.85882354,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7647059 ,\n",
       "       0.3137255 , 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568628, 0.6745098 ,\n",
       "       0.8862745 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.95686275, 0.52156866, 0.04313726, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53333336, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.83137256, 0.5294118 , 0.5176471 , 0.0627451 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f705206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.4136 - accuracy: 0.8764 - val_loss: 0.1609 - val_accuracy: 0.9551\n",
      "Epoch 2/10\n",
      "480/480 [==============================] - 1s 3ms/step - loss: 0.1703 - accuracy: 0.9519 - val_loss: 0.1139 - val_accuracy: 0.9658\n",
      "Epoch 3/10\n",
      "480/480 [==============================] - 1s 3ms/step - loss: 0.1164 - accuracy: 0.9659 - val_loss: 0.0996 - val_accuracy: 0.9697\n",
      "Epoch 4/10\n",
      "480/480 [==============================] - 1s 3ms/step - loss: 0.0891 - accuracy: 0.9741 - val_loss: 0.0883 - val_accuracy: 0.9738\n",
      "Epoch 5/10\n",
      "480/480 [==============================] - 1s 3ms/step - loss: 0.0700 - accuracy: 0.9790 - val_loss: 0.0809 - val_accuracy: 0.9761\n",
      "Epoch 6/10\n",
      "480/480 [==============================] - 2s 3ms/step - loss: 0.0564 - accuracy: 0.9832 - val_loss: 0.0842 - val_accuracy: 0.9757\n",
      "Epoch 7/10\n",
      "480/480 [==============================] - 2s 3ms/step - loss: 0.0469 - accuracy: 0.9859 - val_loss: 0.0805 - val_accuracy: 0.9781\n",
      "Epoch 8/10\n",
      "480/480 [==============================] - 1s 3ms/step - loss: 0.0400 - accuracy: 0.9876 - val_loss: 0.0836 - val_accuracy: 0.9772\n",
      "Epoch 9/10\n",
      "480/480 [==============================] - 1s 3ms/step - loss: 0.0347 - accuracy: 0.9895 - val_loss: 0.0887 - val_accuracy: 0.9787\n",
      "Epoch 10/10\n",
      "480/480 [==============================] - 1s 3ms/step - loss: 0.0294 - accuracy: 0.9904 - val_loss: 0.0815 - val_accuracy: 0.9787\n",
      "313/313 - 0s - loss: 0.0729 - accuracy: 0.9803 - 491ms/epoch - 2ms/step\n",
      "Test loss: 0.07293297350406647\n",
      "Test accuracy: 0.9803000092506409\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(300, activation='relu', input_shape=(28*28,)),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')])  # 0 ~ 9 10개 숫자\n",
    "model.summary()\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=100,\n",
    "                    epochs=10,\n",
    "                    validation_split=0.2)\n",
    "\n",
    "test_scores = model.evaluate(X_test, y_test, verbose=2)\n",
    "print('Test loss:', test_scores[0])\n",
    "print('Test accuracy:', test_scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273130ac",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c4e4483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 5408)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               692352    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 693,962\n",
      "Trainable params: 693,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "550/550 [==============================] - 12s 20ms/step - loss: 0.2521 - accuracy: 0.9255 - val_loss: 0.0846 - val_accuracy: 0.9770\n",
      "Epoch 2/10\n",
      "550/550 [==============================] - 11s 20ms/step - loss: 0.0860 - accuracy: 0.9740 - val_loss: 0.0604 - val_accuracy: 0.9812\n",
      "Epoch 3/10\n",
      "550/550 [==============================] - 12s 21ms/step - loss: 0.0591 - accuracy: 0.9823 - val_loss: 0.0518 - val_accuracy: 0.9838\n",
      "Epoch 4/10\n",
      "550/550 [==============================] - 11s 21ms/step - loss: 0.0446 - accuracy: 0.9861 - val_loss: 0.0456 - val_accuracy: 0.9844\n",
      "Epoch 5/10\n",
      "550/550 [==============================] - 11s 21ms/step - loss: 0.0349 - accuracy: 0.9891 - val_loss: 0.0444 - val_accuracy: 0.9872\n",
      "Epoch 6/10\n",
      "550/550 [==============================] - 11s 21ms/step - loss: 0.0287 - accuracy: 0.9910 - val_loss: 0.0399 - val_accuracy: 0.9894\n",
      "Epoch 7/10\n",
      "550/550 [==============================] - 12s 21ms/step - loss: 0.0253 - accuracy: 0.9913 - val_loss: 0.0404 - val_accuracy: 0.9886\n",
      "Epoch 8/10\n",
      "550/550 [==============================] - 12s 22ms/step - loss: 0.0200 - accuracy: 0.9935 - val_loss: 0.0405 - val_accuracy: 0.9888\n",
      "Epoch 9/10\n",
      "550/550 [==============================] - 11s 20ms/step - loss: 0.0188 - accuracy: 0.9938 - val_loss: 0.0408 - val_accuracy: 0.9888\n",
      "Epoch 10/10\n",
      "550/550 [==============================] - 11s 20ms/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 0.0422 - val_accuracy: 0.9886\n",
      "Test Accuracy:0.9879000186920166\n"
     ]
    }
   ],
   "source": [
    "# CNN으로 숫자 손글씨\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "n_input = 28*28\n",
    "n_L1 = 300\n",
    "n_L2 = 100\n",
    "n_output = 10\n",
    "\n",
    "# 테스트, 훈련 데이터 선언\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# 정규화\n",
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0\n",
    "X_train = X_train[..., tf.newaxis]\n",
    "X_test = X_test[..., tf.newaxis]\n",
    "\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28,28,1)),\n",
    "#   tf.keras.layers.Dense(10, activation='relu', input_shape=(x_tr.shape[0],) dense의 첫 변수가 w의 갯수\n",
    "    tf.keras.layers.MaxPool2D(2, 2), # MAXPool 시행 커널 크기 2, 이동간격 2\n",
    "    tf.keras.layers.Flatten(),      # 입력을 1차원으로 만듬\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu ), \n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(n_output, activation=tf.nn.softmax)\n",
    "])\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',  # optimizer는 대체로 adam이 성능 좋음\n",
    "              loss='sparse_categorical_crossentropy',  # 다항분류 => 원핫 인코딩 안한 경우\n",
    "              metrics=['accuracy']) # 성능 확인\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=100, validation_data=(X_valid, y_valid))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(\"Test Accuracy:{}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b80ab44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# CNN으로 숫자 손글씨\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 28 * 28 픽셀 입력값\n",
    "n_input = 28*28\n",
    "\n",
    "n_L1 = 300\n",
    "n_L2 = 100\n",
    "\n",
    "# 0 ~ 9 정답 10가지 출력값\n",
    "n_output = 10\n",
    "\n",
    "# 테스트, 훈련 데이터 선언\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# 정규화\n",
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "034b00a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# 색상 저장 차원 추가 \n",
    "# Conv2D(32, 3, activation='relu', input_shape=(28,28,1)) 맞추기 위함\n",
    "X_train = X_train[..., tf.newaxis]\n",
    "X_test = X_test[..., tf.newaxis]\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5521c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 색상 저장 쉬운버전.\n",
    "# X_train = X_train.reshape(-1,28,28,1)\n",
    "# X_test = X_test.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20028a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 5408)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               692352    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 693,962\n",
      "Trainable params: 693,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "550/550 [==============================] - 12s 20ms/step - loss: 0.2500 - accuracy: 0.9261 - val_loss: 0.0799 - val_accuracy: 0.9780\n",
      "Epoch 2/10\n",
      "550/550 [==============================] - 11s 20ms/step - loss: 0.0853 - accuracy: 0.9741 - val_loss: 0.0577 - val_accuracy: 0.9830\n",
      "Epoch 3/10\n",
      "550/550 [==============================] - 11s 20ms/step - loss: 0.0609 - accuracy: 0.9814 - val_loss: 0.0477 - val_accuracy: 0.9856\n",
      "Epoch 4/10\n",
      "550/550 [==============================] - 11s 19ms/step - loss: 0.0472 - accuracy: 0.9859 - val_loss: 0.0471 - val_accuracy: 0.9862\n",
      "Epoch 5/10\n",
      "550/550 [==============================] - 11s 19ms/step - loss: 0.0391 - accuracy: 0.9876 - val_loss: 0.0492 - val_accuracy: 0.9854\n",
      "Epoch 6/10\n",
      "550/550 [==============================] - 10s 19ms/step - loss: 0.0323 - accuracy: 0.9897 - val_loss: 0.0428 - val_accuracy: 0.9878\n",
      "Epoch 7/10\n",
      "550/550 [==============================] - 10s 19ms/step - loss: 0.0277 - accuracy: 0.9911 - val_loss: 0.0412 - val_accuracy: 0.9892\n",
      "Epoch 8/10\n",
      "550/550 [==============================] - 11s 19ms/step - loss: 0.0236 - accuracy: 0.9924 - val_loss: 0.0437 - val_accuracy: 0.9872\n",
      "Epoch 9/10\n",
      "550/550 [==============================] - 10s 19ms/step - loss: 0.0207 - accuracy: 0.9930 - val_loss: 0.0471 - val_accuracy: 0.9872\n",
      "Epoch 10/10\n",
      "550/550 [==============================] - 10s 19ms/step - loss: 0.0189 - accuracy: 0.9936 - val_loss: 0.0447 - val_accuracy: 0.9870\n",
      "Test Accuracy:0.9873999953269958\n"
     ]
    }
   ],
   "source": [
    "X_valid, X_train = X_train[:5000], X_train[5000:] # 5천, 5만5천\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:] # 5천, 5만5천\n",
    "\n",
    "# 모델 선언\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28,28,1)), # 이동간격 stride  필터 32회 커널 사이즈 3*3\n",
    "    tf.keras.layers.MaxPool2D(2, 2), # MAXPool 시행, 풀 사이즈 2 stride 2\n",
    "    tf.keras.layers.Flatten(),      # 입력을 1차원으로 만듬\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu ), \n",
    "    tf.keras.layers.Dropout(0.3),   # 30퍼 버리기 => 과적합 경계\n",
    "    tf.keras.layers.Dense(n_output, activation=tf.nn.softmax)   # 결과 10개 미리 선언, 다항분류 => softmax\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 모델 컴파일링\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 모델 fit\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=100, validation_data=(X_valid, y_valid))  \n",
    "# 6만개 100개씩 잘라서 10번 반복\n",
    "# 분할 데이터 직접 줌. => 내부 훈련 데이터를 외부 데이터로 가능.\n",
    "\n",
    "# 모델 평가\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# 테스트 점수\n",
    "print(\"Test Accuracy:{}\".format(test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
